"""
æŒä¹…åŒ–å‘é‡å­˜å‚¨æ¨¡å—ï¼šæ”¯æŒç¦»çº¿å»ºå›¾å’Œåœ¨çº¿æ£€ç´¢
"""
from __future__ import annotations

import uuid
from pathlib import Path
from typing import List, Dict, Set

import chromadb
from chromadb.config import Settings
from langchain_core.documents import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

from src.config import DEVICE, EMBED_MODEL


class PersistentVectorStore:
    """æŒä¹…åŒ– ChromaDB å‘é‡å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, persist_dir: str = "./index/chroma"):
        print(f"ğŸ“¦ åŠ è½½åµŒå…¥æ¨¡å‹: {EMBED_MODEL}")
        self.persist_dir = Path(persist_dir)
        self.persist_dir.mkdir(parents=True, exist_ok=True)
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name=EMBED_MODEL,
            model_kwargs={"device": DEVICE},
            encode_kwargs={"normalize_embeddings": True},
        )
        
        # ä½¿ç”¨æŒä¹…åŒ–å®¢æˆ·ç«¯
        self.chroma_client = chromadb.PersistentClient(
            path=str(self.persist_dir),
            settings=Settings(anonymized_telemetry=False)
        )
        
        self.store = Chroma(
            client=self.chroma_client,
            collection_name="kgprag_index",
            embedding_function=self.embeddings,
        )
        
        try:
            cnt = self.store._collection.count()
            print(f"ğŸ“‚ åŠ è½½æŒä¹…åŒ–å‘é‡åº“: {cnt} ä¸ªæ–‡æ¡£")
        except Exception:
            print("ğŸ“‚ åˆå§‹åŒ–ç©ºå‘é‡åº“")
    
    def reset(self):
        """æ¸…ç©ºå¹¶é‡å»ºé›†åˆ"""
        try:
            self.chroma_client.delete_collection("kgprag_index")
            print("ğŸ—‘ï¸ å·²æ¸…ç©ºå‘é‡åº“")
        except Exception:
            pass
        self.store = Chroma(
            client=self.chroma_client,
            collection_name="kgprag_index",
            embedding_function=self.embeddings,
        )
    
    def embed_query(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡"""
        return self.embeddings.embed_query(text)
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡è·å–æ–‡æœ¬çš„åµŒå…¥å‘é‡ï¼ˆé«˜æ•ˆï¼ŒGPU åˆ©ç”¨ç‡æå‡ 5-10xï¼‰"""
        return self.embeddings.embed_documents(texts)
    
    def add_documents(self, documents: List[Document], ids: List[str]):
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡åº“ (å¸¦åˆ†æ‰¹å¤„ç†)"""
        BATCH_SIZE = 10000  # è®¾ç½®ä¸€ä¸ªå®‰å…¨çš„æ‰¹æ¬¡å¤§å°
        total_docs = len(documents)
        
        for i in range(0, total_docs, BATCH_SIZE):
            batch_docs = documents[i : i + BATCH_SIZE]
            batch_ids = ids[i : i + BATCH_SIZE]
            
            try:
                self.store.add_documents(batch_docs, ids=batch_ids)
                print(f"[Persist] Progress: {min(i + BATCH_SIZE, total_docs)}/{total_docs}")
            except Exception as e:
                print(f"[Persist] Batch {i} failed: {e}")

        try:
            cnt = self.store._collection.count()
            print(f"[Persist] Total Chroma count: {cnt}")
        except Exception as e:
            print(f"[Persist] Chroma count failed: {e}")
    
    def similarity_search_with_score(self, query: str, k: int = 5, filter: Dict = None):
        """ç›¸ä¼¼åº¦æœç´¢"""
        if filter:
            try:
                return self.store.similarity_search_with_score(query, k=k, filter=filter)
            except Exception:
                # filter å¯èƒ½ä¸è¢«æ”¯æŒï¼Œå›é€€
                return self.store.similarity_search_with_score(query, k=k)
        return self.store.similarity_search_with_score(query, k=k)
    
    def hybrid_retrieval(self, user_query: str, context_str: str, visited_ids: Set[str], top_k: int = 5) -> List[Dict]:
        """
        [æ–¹æ¡ˆB] Hybrid Retrieval: ç”¨ç´¯ç§¯ä¸Šä¸‹æ–‡æ„é€ å¢å¼ºæŸ¥è¯¢
        """
        candidates = []
        try:
            context_snippet = context_str[:500].replace("\n", " ").strip()
            enhanced_query = f"{user_query} {context_snippet}"
            
            results = self.store.similarity_search_with_score(enhanced_query, k=top_k * 2)
            
            for doc, score in results:
                d_id = doc.metadata.get("doc_id")
                d_type = doc.metadata.get("type")
                
                if d_id in visited_ids or d_type == "summary":
                    continue
                
                candidates.append({
                    "id": d_id,
                    "text": doc.page_content,
                    "title": doc.metadata.get("title", "VecRetrieval")
                })
                
                if len(candidates) >= top_k:
                    break
            
            if candidates:
                print(f"  ğŸ”„ Hybrid Retrievalè¡¥å……äº† {len(candidates)} ä¸ªå€™é€‰")
                
        except Exception as e:
            print(f"âš ï¸ Hybrid Retrieval Error: {e}")
        
        return candidates
    
    def summary_guided_retrieval(self, user_query: str, graph_store, top_k: int = 5) -> List[Dict]:
        """
        [æ–¹æ¡ˆE] Summary-Guided Top-Down Retrieval
        ä»æ‘˜è¦æ ‘é¡¶å±‚ä¸‹é’»åˆ°å…·ä½“ Chunk
        """
        candidates = []
        try:
            summary_results = self.similarity_search_with_score(
                user_query, 
                k=top_k,
                filter={"type": "summary"}
            )
            
            if not summary_results:
                return []
            
            for summary_doc, score in summary_results:
                summary_id = summary_doc.metadata.get("doc_id")
                children = graph_store.get_summary_children(summary_id)
                
                for child in children:
                    if child["id"].startswith("summary_"):
                        grandchildren = graph_store.get_summary_children(child["id"])
                        for gc in grandchildren:
                            if not gc["id"].startswith("summary_"):
                                candidates.append({
                                    "id": gc["id"],
                                    "text": gc["text"],
                                    "title": "SummaryDrill",
                                    "source_summary": summary_id
                                })
                    else:
                        candidates.append({
                            "id": child["id"],
                            "text": child["text"],
                            "title": "SummaryDrill",
                            "source_summary": summary_id
                        })
                
                if len(candidates) >= top_k * 2:
                    break
            
            if candidates:
                print(f"  ğŸŒ³ Summary-Guided ä¸‹é’»äº† {len(candidates)} ä¸ª Chunk")
                
        except Exception as e:
            print(f"âš ï¸ Summary-Guided Retrieval fallback: {e}")
        
        return candidates[:top_k]
    
    def get_existing_ids(self) -> Set[str]:
        """è·å–å·²å­˜åœ¨çš„æ–‡æ¡£ ID é›†åˆï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰"""
        try:
            collection = self.store._collection
            result = collection.get(include=[])
            return set(result.get("ids", []))
        except Exception as e:
            print(f"âš ï¸ Get existing IDs error: {e}")
            return set()
